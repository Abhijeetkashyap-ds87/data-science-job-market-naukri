
# ğŸ’¼ Naukri.com Job Scraper: Data Science Role Insights

## ğŸ› ï¸ Tech Stack

- **Python**
- **Selenium** â€“ for dynamic web browsing and scraping
- **BeautifulSoup** â€“ for HTML parsing
- **Pandas** â€“ for tabular data handling
- **NumPy** â€“ for missing value handling

---

## ğŸ“Š Project Overview

This project is a **web scraper** built to collect detailed **Data Science job listings** from [Naukri.com](https://www.naukri.com/). The script scrapes multiple pages and compiles a comprehensive dataset with:

- ğŸ§¾ Job Descriptions  
- ğŸ¢ Company Names  
- ğŸ’° Salary Packages  
- ğŸ¯ Experience Requirements  
- ğŸ§  Required Skills  
- ğŸŒ Location  
- ğŸŒŸ Ratings and Reviews  
- ğŸ”— Job URLs

This dataset is exported as `jobs.csv` for further analysis.

---

## ğŸ“‚ Features Scraped

| Feature          | Description                                                    |
|------------------|----------------------------------------------------------------|
| Job Title        | Role name (e.g., Data Scientist, ML Engineer)                  |
| Company Name     | Hiring company                                                 |
| Package          | Annual salary offered                                          |
| Experience       | Experience required (e.g., 1-3 years, 5-10 years)              |
| Skills           | Tags/keywords from job description                             |
| Description      | Summary of responsibilities                                    |
| Rating & Reviews | Company rating and number of reviews                           |
| Location         | Job location (city/region)                                     |
| Job Link         | Direct URL to job post                                         |

---

## ğŸ“ˆ Use Cases

- ğŸ” **Job Market Research**
- ğŸ¤– **Build ML models** to predict salaries or required skills
- ğŸ“š **Resume Matching Systems**
- ğŸ“Š **EDA on skill demand** across job roles
- ğŸ“ **Salary benchmarks by experience and region**

---

## âš™ï¸ How It Works

1. **Browser Initialization**:  
   Opens Chrome in incognito mode using Selenium WebDriver.

2. **Dynamic Page Navigation**:  
   Visits and scrolls through multiple paginated links.

3. **HTML Parsing**:  
   Extracts job details using BeautifulSoup.

4. **Data Storage**:  
   Compiles data in lists â†’ Converts to DataFrame â†’ Saves as `jobs.csv`.

5. **Loop Until Final Page**:  
   Script iterates through pages until a fixed reload count is reached (e.g., 547).

---
